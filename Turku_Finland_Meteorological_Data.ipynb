{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQnhtvmxmZhwHJ7HChO/uD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/Turku_Finland_Meteorological_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KurpWyxle01t",
        "outputId": "5abba6ff-4801-48bb-ab2e-ce3ba73ce10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching 2024 Data for Turku (FMISID: 100949)...\n",
            " > Requesting Weather...\n",
            " > Requesting Solar...\n",
            "   > Resampling Solar to 10-min averages...\n",
            "Merging and filling gaps...\n",
            "Type        Date   Hour  Temperature_C  Global_Radiation_W/m2  Wind_Speed_ms\n",
            "0     2024-01-01  00:00          -15.8                    0.0            1.9\n",
            "1     2024-01-01  00:10          -15.8                    0.0            1.9\n",
            "2     2024-01-01  00:20          -15.7                    0.0            1.9\n",
            "3     2024-01-01  00:30          -15.8                    0.0            1.9\n",
            "4     2024-01-01  00:40          -15.9                    0.0            1.9\n",
            "Total Rows: 52704\n",
            "\n",
            "Success! Saved to Turku_Finland_2024_Filled.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "FMISID = \"100949\"  # Turku Artukainen\n",
        "START_DATE = \"2024-01-01\"\n",
        "END_DATE = \"2025-01-01\"\n",
        "\n",
        "# Define Tasks\n",
        "# Solar is 1-min (needs resampling), Weather is 10-min\n",
        "tasks = [\n",
        "    {\n",
        "        \"name\": \"Weather\",\n",
        "        \"stored_query\": \"fmi::observations::weather::simple\",\n",
        "        \"parameters\": \"t2m,ws_10min\",\n",
        "        \"col_map\": {\"t2m\": \"Temperature_C\", \"ws_10min\": \"Wind_Speed_ms\"}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Solar\",\n",
        "        \"stored_query\": \"fmi::observations::radiation::simple\",\n",
        "        \"parameters\": \"GLOB_1MIN\",\n",
        "        \"col_map\": {\"GLOB_1MIN\": \"Global_Radiation_W/m2\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Helper: Chunk dates to avoid API limits (7 days per chunk)\n",
        "def get_chunks(start_str, end_str):\n",
        "    start = datetime.strptime(start_str, \"%Y-%m-%d\")\n",
        "    end = datetime.strptime(end_str, \"%Y-%m-%d\")\n",
        "    chunks = []\n",
        "    curr = start\n",
        "    while curr < end:\n",
        "        nxt = min(curr + timedelta(days=7), end)\n",
        "        chunks.append((curr.strftime('%Y-%m-%dT%H:%M:%SZ'), nxt.strftime('%Y-%m-%dT%H:%M:%SZ')))\n",
        "        curr = nxt\n",
        "    return chunks\n",
        "\n",
        "chunks = get_chunks(START_DATE, END_DATE)\n",
        "\n",
        "print(f\"Fetching 2024 Data for Turku (FMISID: {FMISID})...\")\n",
        "\n",
        "# --- FETCH FUNCTION ---\n",
        "def fetch_fmi_data(task):\n",
        "    all_rows = []\n",
        "    print(f\" > Requesting {task['name']}...\")\n",
        "\n",
        "    for start, end in chunks:\n",
        "        url = \"http://opendata.fmi.fi/wfs\"\n",
        "        params = {\n",
        "            \"service\": \"WFS\",\n",
        "            \"version\": \"2.0.0\",\n",
        "            \"request\": \"getFeature\",\n",
        "            \"storedquery_id\": task['stored_query'],\n",
        "            \"fmisid\": FMISID,\n",
        "            \"parameters\": task['parameters'],\n",
        "            \"starttime\": start,\n",
        "            \"endtime\": end\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            r = requests.get(url, params=params)\n",
        "            if r.status_code == 200:\n",
        "                root = ET.fromstring(r.content)\n",
        "                for member in root:\n",
        "                    for element in member.iter():\n",
        "                        if 'BsWfsElement' in element.tag:\n",
        "                            timestamp = None\n",
        "                            param = None\n",
        "                            val = None\n",
        "\n",
        "                            for child in element:\n",
        "                                if 'Time' in child.tag: timestamp = child.text\n",
        "                                elif 'ParameterName' in child.tag: param = child.text\n",
        "                                elif 'ParameterValue' in child.tag: val = child.text\n",
        "\n",
        "                            # Handle NaNs from API\n",
        "                            if val == 'NaN': val = None\n",
        "                            else:\n",
        "                                try: val = float(val)\n",
        "                                except: val = None\n",
        "\n",
        "                            if timestamp and param and val is not None:\n",
        "                                friendly_name = task['col_map'].get(param)\n",
        "                                if friendly_name:\n",
        "                                    all_rows.append({'Time': timestamp, 'Type': friendly_name, 'Value': val})\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {e}\")\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "        # Pivot to get columns: Time | Temperature | Wind ...\n",
        "        return df.pivot_table(index='Time', columns='Type', values='Value')\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- EXECUTION ---\n",
        "dfs = []\n",
        "for task in tasks:\n",
        "    df = fetch_fmi_data(task)\n",
        "    if not df.empty:\n",
        "        # If Solar (1-min), average it to 10-min blocks\n",
        "        if \"Global_Radiation_W/m2\" in df.columns:\n",
        "            print(\"   > Resampling Solar to 10-min averages...\")\n",
        "            df = df.resample('10min').mean()\n",
        "\n",
        "        dfs.append(df)\n",
        "\n",
        "# --- MERGE & INTERPOLATE ---\n",
        "if dfs:\n",
        "    print(\"Merging and filling gaps...\")\n",
        "\n",
        "    # 1. Outer Join (Keeps all timestamps)\n",
        "    df_final = pd.concat(dfs, axis=1, join='outer')\n",
        "    df_final = df_final.sort_index()\n",
        "\n",
        "    # 2. CREATE A PERFECT TIME GRID (Optional but recommended)\n",
        "    # This ensures even if API missed a timestamp entirely, we create a row for it\n",
        "    full_range = pd.date_range(start=START_DATE, end=END_DATE, freq='10min', tz='UTC')\n",
        "    df_final = df_final.reindex(full_range)\n",
        "\n",
        "    # 3. LINEAR INTERPOLATION (The Fix)\n",
        "    # limit_direction='both' fills missing values at the very start/end if needed\n",
        "    # No 'limit' argument means it will fill infinite gaps.\n",
        "    df_final = df_final.interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "    # 4. FORMATTING\n",
        "    df_final = df_final.reset_index().rename(columns={'index': 'Time'})\n",
        "    df_final['Date'] = df_final['Time'].dt.strftime('%Y-%m-%d')\n",
        "    df_final['Hour'] = df_final['Time'].dt.strftime('%H:%M')\n",
        "\n",
        "    cols = ['Date', 'Hour', 'Temperature_C', 'Global_Radiation_W/m2', 'Wind_Speed_ms']\n",
        "    df_final = df_final[[c for c in cols if c in df_final.columns]]\n",
        "\n",
        "    # Trim to exactly the requested year (reindexing might add one row at the end)\n",
        "    df_final = df_final[df_final['Date'].str.startswith('2024')]\n",
        "\n",
        "    print(df_final.head())\n",
        "    print(f\"Total Rows: {len(df_final)}\")\n",
        "\n",
        "    filename = \"Turku_Finland_2024_Filled.csv\"\n",
        "    df_final.to_csv(filename, index=False)\n",
        "    print(f\"\\nSuccess! Saved to {filename}\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data.\")"
      ]
    }
  ]
}