{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKGRWeYkyk/byeXQblwLWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/NREL_PVWatts_Batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxlyr4KCnLd0",
        "outputId": "c21b6d46-40da-49fc-fb8e-d71dae382fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching NREL Data (Using 'poa' with Tilt=0 for GHI)...\n",
            "Processing Copenhagen...\n",
            "   > Success! Saved Copenhagen_NREL_TMY.csv\n",
            "Processing Turku...\n",
            "   > Success! Saved Turku_NREL_TMY.csv\n",
            "Processing Stockholm...\n",
            "   > Success! Saved Stockholm_NREL_TMY.csv\n",
            "Processing Oslo...\n",
            "   > Success! Saved Oslo_NREL_TMY.csv\n",
            "\n",
            "All downloads complete.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "API_KEY = \"F34fZ40i424LgdCiWuwPQ9u2MF3mkWBj1NDFP76O\"\n",
        "\n",
        "locations = [\n",
        "    {\"city\": \"Copenhagen\", \"lat\": 55.6761, \"lon\": 12.5683},\n",
        "    {\"city\": \"Turku\",      \"lat\": 60.4518, \"lon\": 22.2666},\n",
        "    {\"city\": \"Stockholm\",  \"lat\": 59.3293, \"lon\": 18.0686},\n",
        "    {\"city\": \"Oslo\",       \"lat\": 59.9139, \"lon\": 10.7522}\n",
        "]\n",
        "\n",
        "url = \"https://developer.nrel.gov/api/pvwatts/v8.json\"\n",
        "\n",
        "print(\"Fetching NREL Data (Using 'poa' with Tilt=0 for GHI)...\")\n",
        "\n",
        "for loc in locations:\n",
        "    city = loc['city']\n",
        "    print(f\"Processing {city}...\")\n",
        "\n",
        "    # Set tilt to 0 so that Plane of Array (POA) = GHI\n",
        "    params = {\n",
        "        \"api_key\": API_KEY,\n",
        "        \"lat\": loc['lat'],\n",
        "        \"lon\": loc['lon'],\n",
        "        \"system_capacity\": 1,\n",
        "        \"azimuth\": 180,\n",
        "        \"tilt\": 0,           # <--- CRITICAL: 0 degree tilt makes POA equal to GHI\n",
        "        \"array_type\": 1,\n",
        "        \"module_type\": 1,\n",
        "        \"losses\": 14,\n",
        "        \"timeframe\": \"hourly\",\n",
        "        \"dataset\": \"intl\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()\n",
        "\n",
        "            # Check for errors returned inside a 200 OK response\n",
        "            if 'errors' in data and data['errors']:\n",
        "                print(f\"   > API Error for {city}: {data['errors']}\")\n",
        "                continue\n",
        "\n",
        "            outputs = data['outputs']\n",
        "\n",
        "            # CORRECTION: We use 'poa' (Plane of Array) instead of 'gh'.\n",
        "            # Since tilt=0, poa IS GHI.\n",
        "            df = pd.DataFrame({\n",
        "                'GHI_Wm2': outputs['poa'],        # Using POA as GHI\n",
        "                'Air_Temperature_C': outputs['tamb'],\n",
        "                'Wind_Speed_ms': outputs['wspd']\n",
        "            })\n",
        "\n",
        "            # Create TMY generic timestamps\n",
        "            # NREL TMY data is always 8760 hours (non-leap year)\n",
        "            df['Month'] = pd.date_range(start='2023-01-01', periods=len(df), freq='h').month\n",
        "            df['Day'] = pd.date_range(start='2023-01-01', periods=len(df), freq='h').day\n",
        "            df['Hour'] = pd.date_range(start='2023-01-01', periods=len(df), freq='h').hour\n",
        "\n",
        "            # Reorder\n",
        "            cols = ['Month', 'Day', 'Hour', 'Air_Temperature_C', 'Wind_Speed_ms', 'GHI_Wm2']\n",
        "            df = df[cols]\n",
        "\n",
        "            filename = f\"{city}_NREL_TMY.csv\"\n",
        "            df.to_csv(filename, index=False)\n",
        "            print(f\"   > Success! Saved {filename}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"   > HTTP Error {r.status_code}: {r.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   > Failed: {e}\")\n",
        "        # Debugging: Print available keys if we fail again\n",
        "        if 'outputs' in locals():\n",
        "            print(f\"     Available keys were: {list(outputs.keys())}\")\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\nAll downloads complete.\")"
      ]
    }
  ]
}