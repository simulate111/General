{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNioS9hJYnLpzHI4MdBd4Cz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/Norway_Oslo_Meteorological_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOYbR_cmORDU",
        "outputId": "3b8d9dbd-23dc-44e3-cc38-2ba9828c50bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for station named 'Sofienberg'...\n",
            "   > Station 'Sofienberg' not found. Using fallback: SN18210\n",
            "Fetching ['Temperature_C'] from SN18210...\n",
            "Fetching ['Wind_Speed_ms', 'Global_Radiation_Wm2'] from SN18700...\n",
            "   WARNING: Column 'Global_Radiation_Wm2' missing for SN18700. Filling with 0.\n",
            "Merging datasets...\n",
            "         Date   Hour  Temperature_C  Global_Radiation_Wm2  Wind_Speed_ms\n",
            "0  2024-01-01  00:00           -4.1                   0.0       7.566667\n",
            "1  2024-01-01  01:00           -4.1                   0.0       7.150000\n",
            "2  2024-01-01  02:00           -4.3                   0.0       7.916667\n",
            "3  2024-01-01  03:00           -4.6                   0.0       8.566667\n",
            "4  2024-01-01  04:00           -4.9                   0.0       9.500000\n",
            "\n",
            "Success! Hybrid weather data saved to Oslo_Hybrid_2024.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "client_id = '95b97914-f898-42d6-b1de-b1557d61357d'\n",
        "\n",
        "# 1. DEFINE STATIONS\n",
        "station_blindern = 'SN18700'\n",
        "target_name = \"Sofienberg\"\n",
        "fallback_station = \"SN18210\" # Oslo - Hovin\n",
        "\n",
        "# 2. HELPER: FIND STATION ID\n",
        "def find_station(name):\n",
        "    print(f\"Searching for station named '{name}'...\")\n",
        "    try:\n",
        "        r = requests.get(\n",
        "            'https://frost.met.no/sources/v0.jsonld',\n",
        "            {'name': name},\n",
        "            auth=(client_id, '')\n",
        "        )\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()['data']\n",
        "            if data:\n",
        "                found_id = data[0]['id']\n",
        "                found_name = data[0]['name']\n",
        "                print(f\"   > Found: {found_name} ({found_id})\")\n",
        "                return found_id\n",
        "    except:\n",
        "        pass\n",
        "    print(f\"   > Station '{name}' not found. Using fallback: {fallback_station}\")\n",
        "    return fallback_station\n",
        "\n",
        "# 3. HELPER: DOWNLOAD & PROCESS RAW DATA\n",
        "def get_hourly_data(station_id, elements, name_map):\n",
        "    all_rows = []\n",
        "    # Monthly chunks\n",
        "    months = [\n",
        "        ('2024-01-01', '2024-02-01'), ('2024-02-01', '2024-03-01'),\n",
        "        ('2024-03-01', '2024-04-01'), ('2024-04-01', '2024-05-01'),\n",
        "        ('2024-05-01', '2024-06-01'), ('2024-06-01', '2024-07-01'),\n",
        "        ('2024-07-01', '2024-08-01'), ('2024-08-01', '2024-09-01'),\n",
        "        ('2024-09-01', '2024-10-01'), ('2024-10-01', '2024-11-01'),\n",
        "        ('2024-11-01', '2024-12-01'), ('2024-12-01', '2025-01-01')\n",
        "    ]\n",
        "\n",
        "    print(f\"Fetching {list(name_map.values())} from {station_id}...\")\n",
        "\n",
        "    for start, end in months:\n",
        "        try:\n",
        "            r = requests.get(\n",
        "                'https://frost.met.no/observations/v0.jsonld',\n",
        "                {'sources': station_id, 'elements': elements, 'referencetime': f\"{start}/{end}\"},\n",
        "                auth=(client_id, '')\n",
        "            )\n",
        "            if r.status_code == 200:\n",
        "                data = r.json().get('data', [])\n",
        "                for item in data:\n",
        "                    ts = item['referenceTime']\n",
        "                    row = {'Time': ts}\n",
        "                    # Extract values\n",
        "                    for obs in item['observations']:\n",
        "                        for k, v in name_map.items():\n",
        "                            if k in obs['elementId']:\n",
        "                                row[v] = obs['value']\n",
        "                    all_rows.append(row)\n",
        "        except Exception as e:\n",
        "            print(f\"   Error fetching chunk {start}: {e}\")\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Process to DataFrame\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "\n",
        "        # --- SAFETY CHECK (The Fix) ---\n",
        "        # Ensure all requested columns exist, even if data was missing\n",
        "        for target_col in name_map.values():\n",
        "            if target_col not in df.columns:\n",
        "                print(f\"   WARNING: Column '{target_col}' missing for {station_id}. Filling with 0.\")\n",
        "                df[target_col] = 0.0\n",
        "\n",
        "        # Resample to Hourly Mean\n",
        "        df = df.set_index('Time').resample('h').mean()\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"   Warning: No data found for {station_id}\")\n",
        "        # Return empty DataFrame with expected columns to prevent crashes\n",
        "        return pd.DataFrame(columns=['Time'] + list(name_map.values()))\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "# Step A: Find the Temperature Station\n",
        "station_temp_id = find_station(target_name)\n",
        "\n",
        "# Step B: Download Temperature (From Sofienberg/Hovin)\n",
        "df_temp = get_hourly_data(\n",
        "    station_temp_id,\n",
        "    'air_temperature',\n",
        "    {'air_temperature': 'Temperature_C'}\n",
        ")\n",
        "\n",
        "# Step C: Download Wind & Radiation (From Blindern)\n",
        "df_blindern = get_hourly_data(\n",
        "    station_blindern,\n",
        "    'wind_speed,surface_downwelling_shortwave_flux_in_air',\n",
        "    {\n",
        "        'wind_speed': 'Wind_Speed_ms',\n",
        "        'surface_downwelling_shortwave_flux_in_air': 'Global_Radiation_Wm2'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Step D: Merge & Format\n",
        "if not df_temp.empty and not df_blindern.empty:\n",
        "    print(\"Merging datasets...\")\n",
        "    df_final = pd.concat([df_temp, df_blindern], axis=1)\n",
        "\n",
        "    # Cleanup\n",
        "    # 1. Fill missing columns if they appeared as NaNs during merge\n",
        "    if 'Global_Radiation_Wm2' not in df_final.columns:\n",
        "         df_final['Global_Radiation_Wm2'] = 0.0\n",
        "\n",
        "    df_final = df_final.interpolate(method='linear', limit=2)\n",
        "    df_final['Global_Radiation_Wm2'] = df_final['Global_Radiation_Wm2'].fillna(0)\n",
        "    df_final.loc[df_final['Global_Radiation_Wm2'] < 0, 'Global_Radiation_Wm2'] = 0\n",
        "    df_final = df_final.dropna(how='all')\n",
        "\n",
        "    # Format Date/Hour\n",
        "    df_final = df_final.reset_index()\n",
        "    df_final['Date'] = df_final['Time'].dt.strftime('%Y-%m-%d')\n",
        "    df_final['Hour'] = df_final['Time'].dt.strftime('%H:%M')\n",
        "\n",
        "    # Order Columns\n",
        "    cols = ['Date', 'Hour', 'Temperature_C', 'Global_Radiation_Wm2', 'Wind_Speed_ms']\n",
        "    # Select only columns that actually exist\n",
        "    cols = [c for c in cols if c in df_final.columns]\n",
        "    df_final = df_final[cols]\n",
        "\n",
        "    print(df_final.head())\n",
        "\n",
        "    filename = \"Oslo_Hybrid_2024.csv\"\n",
        "    df_final.to_csv(filename, index=False)\n",
        "    print(f\"\\nSuccess! Hybrid weather data saved to {filename}\")\n",
        "else:\n",
        "    print(\"Failed to get data.\")"
      ]
    }
  ]
}