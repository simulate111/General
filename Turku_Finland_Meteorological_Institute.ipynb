{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT3ek8tZOnq/jLlVISUapN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/Turku_Finland_Meteorological_Institute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxlyr4KCnLd0",
        "outputId": "7765c5a9-d5d0-406e-d441-7244b37d960f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fetching 2024 Data for Turku (FMISID: 100949) ---\n",
            "\n",
            "> Fetching Weather...\n",
            "   Chunk 1/53...\n",
            "   Chunk 11/53...\n",
            "   Chunk 21/53...\n",
            "   Chunk 31/53...\n",
            "   Chunk 41/53...\n",
            "   Chunk 51/53...\n",
            "\n",
            "> Fetching Solar...\n",
            "   Chunk 1/53...\n",
            "   Chunk 11/53...\n",
            "   Chunk 21/53...\n",
            "   Chunk 31/53...\n",
            "   Chunk 41/53...\n",
            "   Chunk 51/53...\n",
            "   > Resampling Solar (1-min) to 10-min averages...\n",
            "\n",
            "Merging datasets...\n",
            "------------------------------\n",
            "Type        Date   Hour  Temperature_C  Wind_Speed_ms  GHI_Wm2\n",
            "0     2024-01-01  00:00          -15.8            1.9      0.0\n",
            "1     2024-01-01  00:10          -15.8            1.9      0.0\n",
            "2     2024-01-01  00:20          -15.7            1.9      0.0\n",
            "3     2024-01-01  00:30          -15.8            1.9      0.0\n",
            "4     2024-01-01  00:40          -15.9            1.9      0.0\n",
            "------------------------------\n",
            "Success! Saved to Turku_Artukainen_2024.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from datetime import datetime, timedelta, UTC\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "STATION_ID = \"100949\"  # Turku Artukainen\n",
        "START_DATE = \"2024-01-01\"\n",
        "END_DATE = \"2025-01-01\"\n",
        "\n",
        "print(f\"--- Fetching 2024 Data for Turku (FMISID: {STATION_ID}) ---\")\n",
        "\n",
        "# Define Fetch Tasks\n",
        "tasks = [\n",
        "    {\n",
        "        \"name\": \"Weather\",\n",
        "        \"query\": \"fmi::observations::weather::simple\",\n",
        "        \"params\": \"t2m,ws_10min\",\n",
        "        \"map\": {\"t2m\": \"Temperature_C\", \"ws_10min\": \"Wind_Speed_ms\"}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Solar\",\n",
        "        \"query\": \"fmi::observations::radiation::simple\",\n",
        "        \"params\": \"GLOB_1MIN\", # 1-minute resolution GHI\n",
        "        \"map\": {\"GLOB_1MIN\": \"GHI_Wm2\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Helper: Chunk dates (7 days per chunk to stay within FMI limits)\n",
        "def get_chunks(start, end):\n",
        "    s = datetime.strptime(start, \"%Y-%m-%d\").replace(tzinfo=UTC)\n",
        "    e = datetime.strptime(end, \"%Y-%m-%d\").replace(tzinfo=UTC)\n",
        "    chunks = []\n",
        "    curr = s\n",
        "    while curr < e:\n",
        "        nxt = min(curr + timedelta(days=7), e)\n",
        "        chunks.append((curr.strftime('%Y-%m-%dT%H:%M:%SZ'), nxt.strftime('%Y-%m-%dT%H:%M:%SZ')))\n",
        "        curr = nxt\n",
        "    return chunks\n",
        "\n",
        "chunks = get_chunks(START_DATE, END_DATE)\n",
        "\n",
        "# --- FETCHING LOOP ---\n",
        "dfs = []\n",
        "\n",
        "for task in tasks:\n",
        "    print(f\"\\n> Fetching {task['name']}...\")\n",
        "    all_rows = []\n",
        "\n",
        "    total = len(chunks)\n",
        "    for i, (start_str, end_str) in enumerate(chunks):\n",
        "        # Progress bar\n",
        "        if i % 10 == 0: print(f\"   Chunk {i+1}/{total}...\")\n",
        "\n",
        "        url = \"http://opendata.fmi.fi/wfs\"\n",
        "        params = {\n",
        "            \"service\": \"WFS\", \"version\": \"2.0.0\", \"request\": \"getFeature\",\n",
        "            \"storedquery_id\": task['query'],\n",
        "            \"fmisid\": STATION_ID,\n",
        "            \"parameters\": task['params'],\n",
        "            \"starttime\": start_str, \"endtime\": end_str\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            r = requests.get(url, params=params)\n",
        "            if r.status_code == 200:\n",
        "                root = ET.fromstring(r.content)\n",
        "                ns = {'wfs': 'http://www.opengis.net/wfs/2.0', 'BsWfs': 'http://xml.fmi.fi/schema/wfs/2.0'}\n",
        "\n",
        "                for member in root.findall('.//wfs:member', ns):\n",
        "                    elm = member.find('.//BsWfs:BsWfsElement', ns)\n",
        "                    if elm is not None:\n",
        "                        t = elm.find('BsWfs:Time', ns).text\n",
        "                        p = elm.find('BsWfs:ParameterName', ns).text\n",
        "                        v_node = elm.find('BsWfs:ParameterValue', ns)\n",
        "                        v = v_node.text if v_node is not None else \"NaN\"\n",
        "\n",
        "                        if v == 'NaN': v = None\n",
        "                        else:\n",
        "                            try: v = float(v)\n",
        "                            except: v = None\n",
        "\n",
        "                        if t and p and v is not None:\n",
        "                            friendly = task['map'].get(p)\n",
        "                            if friendly:\n",
        "                                all_rows.append({'Time': t, 'Type': friendly, 'Value': v})\n",
        "        except Exception as e:\n",
        "            print(f\"   Error in chunk {i}: {e}\")\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    # Process Data\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "        df = df.pivot_table(index='Time', columns='Type', values='Value')\n",
        "\n",
        "        # If Solar, resample 1-min -> 10-min to match weather\n",
        "        if 'GHI_Wm2' in df.columns:\n",
        "            print(\"   > Resampling Solar (1-min) to 10-min averages...\")\n",
        "            df = df.resample('10min').mean()\n",
        "\n",
        "        dfs.append(df)\n",
        "\n",
        "# --- MERGE & SAVE ---\n",
        "if dfs:\n",
        "    print(\"\\nMerging datasets...\")\n",
        "    df_final = pd.concat(dfs, axis=1).sort_index()\n",
        "\n",
        "    # 1. Create perfect time grid (avoids missing rows)\n",
        "    full_range = pd.date_range(START_DATE, END_DATE, freq='10min', tz='UTC')\n",
        "    df_final = df_final.reindex(full_range)\n",
        "\n",
        "    # 2. Interpolate gaps\n",
        "    df_final = df_final.interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "    # 3. Clean Radiation (No negative values at night)\n",
        "    if 'GHI_Wm2' in df_final.columns:\n",
        "        df_final['GHI_Wm2'] = df_final['GHI_Wm2'].clip(lower=0).fillna(0)\n",
        "\n",
        "    # 4. Format\n",
        "    df_final = df_final.reset_index().rename(columns={'index': 'Time'})\n",
        "    df_final['Date'] = df_final['Time'].dt.strftime('%Y-%m-%d')\n",
        "    df_final['Hour'] = df_final['Time'].dt.strftime('%H:%M')\n",
        "\n",
        "    # 5. Filter & Select Columns\n",
        "    df_final = df_final[df_final['Date'].str.startswith('2024')]\n",
        "    cols = ['Date', 'Hour', 'Temperature_C', 'Wind_Speed_ms', 'GHI_Wm2']\n",
        "    df_final = df_final[[c for c in cols if c in df_final.columns]]\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(df_final.head())\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    filename = \"Turku_Artukainen_2024.csv\"\n",
        "    df_final.to_csv(filename, index=False)\n",
        "    print(f\"Success! Saved to {filename}\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data.\")"
      ]
    }
  ]
}