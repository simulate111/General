{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGS3Ae6FOTkACcK1kYOugI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/Turku_ERA5_CDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"cdsapi>=0.7.7\""
      ],
      "metadata": {
        "id": "ejepqwjFn8Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4484a72-3434-440f-dcc4-a6195fa1ff33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cdsapi>=0.7.7 in /usr/local/lib/python3.12/dist-packages (0.7.7)\n",
            "Requirement already satisfied: ecmwf-datastores-client>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (4.67.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (25.4.0)\n",
            "Requirement already satisfied: multiurl>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2025.11.12)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4"
      ],
      "metadata": {
        "id": "RvPUR0yStJcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e999d92-a0ff-44c3-cb95-caae08433f5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.12/dist-packages (1.7.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netcdf4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2025.11.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Updated configuration: removed the UID prefix as per the error instructions\n",
        "content = \"\"\"url: https://cds.climate.copernicus.eu/api\n",
        "key: c025f203-5930-4d9c-acd6-699c46be7fd8\"\"\"\n",
        "\n",
        "with open(os.path.expanduser('~/.cdsapirc'), 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Configuration updated! Now attempting to update the library...\")\n",
        "\n",
        "# Also update your library to the latest version to match the new API\n",
        "!pip install --upgrade cdsapi"
      ],
      "metadata": {
        "id": "xsU63P_1qIQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05ba5e8-a629-4e8c-e8ec-6a95f1152c41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration updated! Now attempting to update the library...\n",
            "Requirement already satisfied: cdsapi in /usr/local/lib/python3.12/dist-packages (0.7.7)\n",
            "Requirement already satisfied: ecmwf-datastores-client>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi) (4.67.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (25.4.0)\n",
            "Requirement already satisfied: multiurl>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2025.11.12)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "import os\n",
        "import calendar\n",
        "\n",
        "# CRITICAL FIX: Set progress=False to prevent widget metadata creation\n",
        "c = cdsapi.Client(progress=False)\n",
        "\n",
        "# Range: Full year 2024 + January 2025\n",
        "tasks = [('2024', str(m).zfill(2)) for m in range(1, 13)] + [('2025', '01')]\n",
        "\n",
        "print(\"--- Data Download Started (GitHub-Safe Mode) ---\")\n",
        "\n",
        "for i, (year, month) in enumerate(tasks):\n",
        "    filename = f'turku_{year}_{month}.nc'\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"[{i+1}/13] {filename} already exists. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Determine days: Full month for 2024, but only Jan 1st for 2025\n",
        "    if year == '2025':\n",
        "        days = ['01']\n",
        "    else:\n",
        "        last_day = calendar.monthrange(int(year), int(month))[1]\n",
        "        days = [str(d).zfill(2) for d in range(1, last_day + 1)]\n",
        "\n",
        "    print(f\"[{i+1}/13] Requesting {month}/{year}...\")\n",
        "\n",
        "    try:\n",
        "        c.retrieve(\n",
        "            'reanalysis-era5-land',\n",
        "            {\n",
        "                'variable': [\n",
        "                    '2m_temperature',\n",
        "                    '10m_u_component_of_wind',\n",
        "                    '10m_v_component_of_wind',\n",
        "                    'surface_solar_radiation_downwards',\n",
        "                ],\n",
        "                'year': year,\n",
        "                'month': month,\n",
        "                'day': days,\n",
        "                'time': [f\"{str(h).zfill(2)}:00\" for h in range(24)],\n",
        "                'area': [60.5, 22.5, 60.5, 22.5],\n",
        "                'format': 'netcdf',\n",
        "            },\n",
        "            filename)\n",
        "        # We print a success message that will stay in your GitHub logs\n",
        "        print(f\"      ‚úÖ {filename} successfully downloaded and saved.\")\n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ùå Failed {year}-{month}: {e}\")\n",
        "\n",
        "print(\"--- All Downloads Complete ---\")"
      ],
      "metadata": {
        "id": "FMNRWkaGoHXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac1038d-2f39-4903-d7a0-714b7b89feac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-20 05:48:21,144 INFO [2025-12-03T00:00:00Z] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-03T00:00:00Z] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Download Started (GitHub-Safe Mode) ---\n",
            "[1/13] Requesting 01/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-20 05:48:21,585 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2025-12-20 05:48:21,587 INFO Request ID is d20faa97-2da8-47ac-a360-9340d353e191\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is d20faa97-2da8-47ac-a360-9340d353e191\n",
            "2025-12-20 05:48:21,786 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-12-20 05:48:35,995 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4 h5netcdf"
      ],
      "metadata": {
        "id": "BEbXSK_zQsp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 1. Setup paths\n",
        "file_list = sorted(glob.glob('turku_*.nc'))\n",
        "extract_dir = 'extracted_temp'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "all_data = []\n",
        "\n",
        "print(f\"Checking {len(file_list)} files for ZIP compression...\")\n",
        "\n",
        "for f in file_list:\n",
        "    try:\n",
        "        # Check if the file is actually a ZIP (first two bytes are 'PK')\n",
        "        with open(f, 'rb') as test_f:\n",
        "            is_zip = test_f.read(2) == b'PK'\n",
        "\n",
        "        if is_zip:\n",
        "            print(f\"üì¶ {f} is a ZIP archive. Extracting...\")\n",
        "            with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "            # Find the actual .nc file that was inside the ZIP\n",
        "            inner_files = glob.glob(os.path.join(extract_dir, \"*.nc\"))\n",
        "            if inner_files:\n",
        "                # Process the extracted file\n",
        "                ds = xr.open_dataset(inner_files[0], engine='netcdf4')\n",
        "                df = ds.to_dataframe().reset_index()\n",
        "                all_data.append(df)\n",
        "                print(f\"‚úÖ Successfully read data from inside {f}\")\n",
        "\n",
        "                # Clean up extracted file to save space\n",
        "                for extra in inner_files:\n",
        "                    os.remove(extra)\n",
        "        else:\n",
        "            # It's a normal NetCDF file\n",
        "            ds = xr.open_dataset(f, engine='netcdf4')\n",
        "            df = ds.to_dataframe().reset_index()\n",
        "            all_data.append(df)\n",
        "            print(f\"‚úÖ Successfully read normal NetCDF: {f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {f}: {e}\")\n",
        "\n",
        "# 2. Final Merge and Conversion\n",
        "if all_data:\n",
        "    df_combined = pd.concat(all_data).sort_values('valid_time')\n",
        "\n",
        "    # Conversions\n",
        "    df_combined['Air_Temp_C'] = df_combined['t2m'] - 273.15\n",
        "    df_combined['Wind_Speed_ms'] = np.sqrt(df_combined['u10']**2 + df_combined['v10']**2)\n",
        "    df_combined['GHI_Wm2'] = df_combined['ssrd'] / 3600\n",
        "\n",
        "    # Clean up and Export\n",
        "    final_output = df_combined[['valid_time', 'Air_Temp_C', 'Wind_Speed_ms', 'GHI_Wm2']]\n",
        "    final_output.columns = ['Timestamp', 'Air_Temp_C', 'Wind_Speed_ms', 'GHI_W_m2']\n",
        "\n",
        "    final_output.to_csv('Turku_Final_Weather_2024.csv', index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"SUCCESS! Final CSV created.\")\n",
        "    print(f\"Total rows: {len(final_output)}\")\n",
        "    print(\"=\"*30)\n",
        "    print(final_output.head())\n",
        "else:\n",
        "    print(\"üõë No data frames were created. Check if files are 0 KB.\")"
      ],
      "metadata": {
        "id": "eyrOqHk1sSjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "432p5jDJSAqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 1. Get the name of your current notebook\n",
        "# If you are in Colab, it is usually 'Untitled.ipynb' unless you renamed it\n",
        "notebook_path = 'your_notebook_name.ipynb'\n",
        "\n",
        "try:\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "        nb_data = json.load(f)\n",
        "\n",
        "    # 2. Check if the 'widgets' key exists in metadata and remove it\n",
        "    if 'widgets' in nb_data.get('metadata', {}):\n",
        "        del nb_data['metadata']['widgets']\n",
        "        print(\"‚úÖ Success: Broken widget metadata removed.\")\n",
        "\n",
        "        # 3. Save the notebook back to disk\n",
        "        with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(nb_data, f, indent=1)\n",
        "        print(\"‚ú® Notebook is now GitHub-safe. You can now push/upload it.\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è No widget metadata found. The error might be in the file name or a specific cell's output.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Could not find '{notebook_path}'. Please check the filename in the sidebar.\")"
      ],
      "metadata": {
        "id": "Q3zBt6pWRZ9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}