{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Sweden_stockholm_meteorological_data_SMHI(2015-2025).ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Climatic_Data/blob/main/Sweden_stockholm_meteorological_data_SMHI(2015_2025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H9dYK3rxU1N",
        "outputId": "c75571ee-5ed6-42f7-8194-b629987dc3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Fetching Air_Temperature_C from Station 98230...\n",
            " > Fetching Wind_Speed_ms from Station 97200...\n",
            " > Fetching Solar Data (STRÅNG)... This may take a moment.\n",
            "   ...fetching solar for 2015\n",
            "   ...fetching solar for 2016\n",
            "   ...fetching solar for 2017\n",
            "   ...fetching solar for 2018\n",
            "   ...fetching solar for 2019\n",
            "   ...fetching solar for 2020\n",
            "   ...fetching solar for 2021\n",
            "   ...fetching solar for 2022\n",
            "   ...fetching solar for 2023\n",
            "   ...fetching solar for 2024\n",
            "Merging data...\n",
            "Calculating 10-year Hourly Averages...\n",
            "Success! Created 8784 hourly average rows.\n",
            "  Display_Date Display_Hour  Air_Temperature_C  Wind_Speed_ms  \\\n",
            "0        01-01        00:00               2.79       3.100000   \n",
            "1        01-01        01:00               2.82       3.400000   \n",
            "2        01-01        02:00               2.79       3.400000   \n",
            "3        01-01        03:00               2.81       4.111111   \n",
            "4        01-01        04:00               2.69       3.333333   \n",
            "\n",
            "   Global_Solar_Wm2  \n",
            "0               0.0  \n",
            "1               0.0  \n",
            "2               0.0  \n",
            "3               0.0  \n",
            "4               0.0  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE = \"2024-12-31\"\n",
        "\n",
        "# COORDINATES (Stockholm)\n",
        "LAT = \"59.3417\"\n",
        "LON = \"18.0549\"\n",
        "\n",
        "# TASKS\n",
        "tasks = [\n",
        "    # 1. Temperature: Observatoriekullen (Station 98230) - Best for City Temp\n",
        "    {\"station\": \"98230\", \"param\": \"1\", \"name\": \"Air_Temperature_C\"},\n",
        "    # 2. Wind: Bromma Airport (Station 97200) - Best for Wind\n",
        "    {\"station\": \"97200\", \"param\": \"4\", \"name\": \"Wind_Speed_ms\"}\n",
        "]\n",
        "\n",
        "def fetch_smhi_data(task):\n",
        "    \"\"\"Fetches observed data (Archive + Latest)\"\"\"\n",
        "    print(f\" > Fetching {task['name']} from Station {task['station']}...\")\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # A. Try Archive (CSV) - Contains years of history\n",
        "    url_csv = f\"https://opendata-download-metobs.smhi.se/api/version/1.0/parameter/{task['param']}/station/{task['station']}/period/corrected-archive/data.csv\"\n",
        "    try:\n",
        "        r = requests.get(url_csv)\n",
        "        if r.status_code == 200:\n",
        "            content = r.text\n",
        "            # Find the start of data rows\n",
        "            skip_rows = 0\n",
        "            for i, line in enumerate(content.splitlines()[:50]):\n",
        "                if \"Datum\" in line or \"Date\" in line:\n",
        "                    skip_rows = i\n",
        "                    break\n",
        "\n",
        "            df = pd.read_csv(io.StringIO(content), sep=';', skiprows=skip_rows,\n",
        "                             usecols=[0,1,2], names=['d', 't', 'v'], dtype=str)\n",
        "\n",
        "            # FAST FIX: Explicitly specify format to avoid warning\n",
        "            df['Time'] = pd.to_datetime(df['d'] + ' ' + df['t'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "            df['Value'] = pd.to_numeric(df['v'], errors='coerce')\n",
        "            combined_df = pd.concat([combined_df, df[['Time', 'Value']]])\n",
        "    except Exception as e: print(f\"   Error fetching archive: {e}\")\n",
        "\n",
        "    # B. Try Latest (JSON) - Last 4 months\n",
        "    url_json = f\"https://opendata-download-metobs.smhi.se/api/version/1.0/parameter/{task['param']}/station/{task['station']}/period/latest-months/data.json\"\n",
        "    try:\n",
        "        r = requests.get(url_json)\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()\n",
        "            records = [{'Time': pd.to_datetime(i['date'], unit='ms'), 'Value': float(i['value'])} for i in data['value']]\n",
        "            combined_df = pd.concat([combined_df, pd.DataFrame(records)])\n",
        "    except Exception: pass\n",
        "\n",
        "    # C. Process\n",
        "    if not combined_df.empty:\n",
        "        combined_df = combined_df.dropna(subset=['Time']).sort_values('Time').drop_duplicates(subset=['Time'])\n",
        "        combined_df = combined_df.set_index('Time').resample('h').mean()\n",
        "        combined_df.index = combined_df.index.tz_localize(None) # Ensure UTC/Naive\n",
        "        return combined_df.rename(columns={'Value': task['name']})\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def fetch_strang_solar_multiyear(lat, lon, start, end):\n",
        "    \"\"\"Fetches Solar from STRÅNG Model year-by-year to prevent timeouts\"\"\"\n",
        "    print(\" > Fetching Solar Data (STRÅNG)... This may take a moment.\")\n",
        "    all_solar = []\n",
        "\n",
        "    start_dt = pd.to_datetime(start)\n",
        "    end_dt = pd.to_datetime(end)\n",
        "\n",
        "    # Generate year intervals\n",
        "    years = pd.date_range(start=start_dt, end=end_dt, freq='YS')\n",
        "\n",
        "    for yr in years:\n",
        "        y_start = yr.strftime('%Y-%m-%d')\n",
        "        y_end = (yr + pd.offsets.YearEnd(0)).strftime('%Y-%m-%d')\n",
        "        print(f\"   ...fetching solar for {yr.year}\")\n",
        "\n",
        "        url = f\"https://opendata-download-metanalys.smhi.se/api/category/strang1g/version/1/geotype/point/lon/{lon}/lat/{lat}/parameter/117/data.json\"\n",
        "        params = {'from': y_start.replace(\"-\", \"\"), 'to': y_end.replace(\"-\", \"\"), 'interval': 'hourly'}\n",
        "\n",
        "        try:\n",
        "            r = requests.get(url, params=params)\n",
        "            if r.status_code == 200:\n",
        "                data = r.json()\n",
        "                records = [{'Time': pd.to_datetime(i['date_time']), 'Global_Solar_Wm2': i['value']} for i in data]\n",
        "                df = pd.DataFrame(records)\n",
        "                all_solar.append(df)\n",
        "        except Exception: pass\n",
        "\n",
        "    if all_solar:\n",
        "        full_df = pd.concat(all_solar)\n",
        "        full_df['Time'] = full_df['Time'].dt.tz_localize(None)\n",
        "        return full_df.set_index('Time').resample('h').mean()\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "# 1. Fetch Data\n",
        "dfs = []\n",
        "for task in tasks:\n",
        "    dfs.append(fetch_smhi_data(task))\n",
        "\n",
        "dfs.append(fetch_strang_solar_multiyear(LAT, LON, START_DATE, END_DATE))\n",
        "\n",
        "print(\"Merging data...\")\n",
        "df_raw = pd.concat(dfs, axis=1)\n",
        "\n",
        "# 2. Filter strict range (2015-2024)\n",
        "mask = (df_raw.index >= pd.Timestamp(START_DATE)) & (df_raw.index <= pd.Timestamp(f\"{END_DATE} 23:59:59\"))\n",
        "df_raw = df_raw.loc[mask]\n",
        "\n",
        "# 3. Cleanup (Interpolate small gaps)\n",
        "df_raw = df_raw.interpolate(method='time', limit=3)\n",
        "if 'Global_Solar_Wm2' in df_raw.columns:\n",
        "    df_raw['Global_Solar_Wm2'] = df_raw['Global_Solar_Wm2'].fillna(0).clip(lower=0)\n",
        "\n",
        "# 4. Calculate 10-Year Hourly Average\n",
        "print(\"Calculating 10-year Hourly Averages...\")\n",
        "\n",
        "# Group by Month, Day, Hour\n",
        "grouped = df_raw.groupby([df_raw.index.month, df_raw.index.day, df_raw.index.hour]).mean()\n",
        "grouped.index.names = ['Month', 'Day', 'Hour']\n",
        "df_avg = grouped.reset_index()\n",
        "\n",
        "# Create dummy timestamp for display (using 2024 to handle Leap Years safely)\n",
        "df_avg['Dummy_Timestamp'] = pd.to_datetime(\n",
        "    '2024-' + df_avg['Month'].astype(str) + '-' + df_avg['Day'].astype(str) + ' ' + df_avg['Hour'].astype(str) + ':00:00',\n",
        "    errors='coerce'\n",
        ")\n",
        "df_avg = df_avg.dropna(subset=['Dummy_Timestamp']).sort_values('Dummy_Timestamp')\n",
        "\n",
        "# Format Output\n",
        "df_avg['Display_Date'] = df_avg['Dummy_Timestamp'].dt.strftime('%m-%d')\n",
        "df_avg['Display_Hour'] = df_avg['Dummy_Timestamp'].dt.strftime('%H:%M')\n",
        "final_output = df_avg[['Display_Date', 'Display_Hour', 'Air_Temperature_C', 'Wind_Speed_ms', 'Global_Solar_Wm2']]\n",
        "\n",
        "print(f\"Success! Created {len(final_output)} hourly average rows.\")\n",
        "print(final_output.head())\n",
        "final_output.to_csv(\"Stockholm_10Year_Hourly_Average_2015-2024.csv\", index=False)"
      ]
    }
  ]
}