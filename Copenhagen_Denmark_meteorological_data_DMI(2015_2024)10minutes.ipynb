{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Copenhagen_Denmark_meteorological_data_DMI(2015-2024)10minutes.ipynb",
      "authorship_tag": "ABX9TyP3ZWWJKoFuAG4SXt43US96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Climatic_Data/blob/main/Copenhagen_Denmark_meteorological_data_DMI(2015_2024)10minutes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H9dYK3rxU1N",
        "outputId": "3b6a5118-472c-4853-c5a4-6c25399781b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Extraction (2015-2024)...\n",
            "\n",
            "Processing Temperature_C (Station 06180):\n",
            "   > Fetching 2015... OK (52561 rows)\n",
            "   > Fetching 2016... OK (52705 rows)\n",
            "   > Fetching 2017... OK (52561 rows)\n",
            "   > Fetching 2018... OK (52561 rows)\n",
            "   > Fetching 2019... OK (52561 rows)\n",
            "   > Fetching 2020... OK (52705 rows)\n",
            "   > Fetching 2021... OK (52561 rows)\n",
            "   > Fetching 2022... OK (52561 rows)\n",
            "   > Fetching 2023... OK (52561 rows)\n",
            "   > Fetching 2024... OK (52704 rows)\n",
            "\n",
            "Processing Wind_Speed_ms (Station 06180):\n",
            "   > Fetching 2015... OK (52561 rows)\n",
            "   > Fetching 2016... OK (52705 rows)\n",
            "   > Fetching 2017... OK (52561 rows)\n",
            "   > Fetching 2018... OK (52561 rows)\n",
            "   > Fetching 2019... OK (52561 rows)\n",
            "   > Fetching 2020... OK (52705 rows)\n",
            "   > Fetching 2021... OK (52561 rows)\n",
            "   > Fetching 2022... OK (52561 rows)\n",
            "   > Fetching 2023... OK (52561 rows)\n",
            "   > Fetching 2024... OK (52704 rows)\n",
            "\n",
            "Processing Global_Radiation_Wm2 (Station 06187):\n",
            "   > Fetching 2015... OK (52561 rows)\n",
            "   > Fetching 2016... OK (52705 rows)\n",
            "   > Fetching 2017... OK (52561 rows)\n",
            "   > Fetching 2018... OK (52561 rows)\n",
            "   > Fetching 2019... OK (52555 rows)\n",
            "   > Fetching 2020... OK (52699 rows)\n",
            "   > Fetching 2021... OK (52561 rows)\n",
            "   > Fetching 2022... OK (52561 rows)\n",
            "   > Fetching 2023... OK (52561 rows)\n",
            "   > Fetching 2024... OK (52705 rows)\n",
            "\n",
            "Merging all parameters...\n",
            "Calculating 10-year 10-Minute Averages...\n",
            "Success! Created 52704 rows (10-min resolution).\n",
            "  Display_Date Display_Time  Temperature_C  Wind_Speed_ms  \\\n",
            "0        01-01        00:00           5.64           4.94   \n",
            "1        01-01        00:10           5.58           5.10   \n",
            "2        01-01        00:20           5.52           5.34   \n",
            "3        01-01        00:30           5.56           5.45   \n",
            "4        01-01        00:40           5.65           5.35   \n",
            "\n",
            "   Global_Radiation_Wm2  \n",
            "0                   0.1  \n",
            "1                   0.1  \n",
            "2                   0.1  \n",
            "3                   0.1  \n",
            "4                   0.1  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "START_YEAR = 2015\n",
        "END_YEAR = 2024\n",
        "API_KEY = \"\"  # Paste your DMI API Key here if you encounter 401 errors\n",
        "BASE_URL = \"https://opendataapi.dmi.dk/v2/metObs/collections/observation/items\"\n",
        "\n",
        "# TASKS\n",
        "tasks = [\n",
        "    # Station 06180 (Copenhagen Airport)\n",
        "    {\"station\": \"06180\", \"param\": \"temp_dry\",   \"name\": \"Temperature_C\"},\n",
        "    {\"station\": \"06180\", \"param\": \"wind_speed\", \"name\": \"Wind_Speed_ms\"},\n",
        "    # Station 06187 (Copenhagen Toldbod)\n",
        "    {\"station\": \"06187\", \"param\": \"radia_glob_past1h\", \"name\": \"Global_Radiation_Wm2\"}\n",
        "]\n",
        "\n",
        "def fetch_dmi_year(year, task):\n",
        "    \"\"\"Fetches one year of data and condenses to 10-Minute averages immediately\"\"\"\n",
        "    start_str = f\"{year}-01-01T00:00:00Z\"\n",
        "    end_str = f\"{year+1}-01-01T00:00:00Z\"\n",
        "\n",
        "    params = {\n",
        "        \"stationId\": task['station'],\n",
        "        \"datetime\": f\"{start_str}/{end_str}\",\n",
        "        \"parameterId\": task['param'],\n",
        "        \"limit\": 300000,\n",
        "    }\n",
        "\n",
        "    headers = {'X-Gravitee-Api-Key': API_KEY} if API_KEY else {}\n",
        "    print(f\"   > Fetching {year}...\", end=\" \", flush=True)\n",
        "\n",
        "    try:\n",
        "        r = requests.get(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "        # Fallback for Radiation\n",
        "        if r.status_code != 200 and task['name'] == \"Global_Radiation_Wm2\":\n",
        "            params['parameterId'] = 'radia_glob'\n",
        "            r = requests.get(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            data = r.json().get('features', [])\n",
        "            if not data:\n",
        "                print(\"No data.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            records = [{\n",
        "                'Time': item['properties']['observed'],\n",
        "                task['name']: item['properties']['value']\n",
        "            } for item in data]\n",
        "\n",
        "            df = pd.DataFrame(records)\n",
        "            df['Time'] = pd.to_datetime(df['Time'])\n",
        "\n",
        "            # --- CHANGED TO 10 MINUTES ---\n",
        "            # '10min' snaps timestamps to 00:00, 00:10, 00:20...\n",
        "            df = df.set_index('Time').resample('10min').mean()\n",
        "            print(f\"OK ({len(df)} rows)\")\n",
        "            return df\n",
        "        else:\n",
        "            print(f\"Error {r.status_code}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- 1. FETCH DATA ---\n",
        "all_data = []\n",
        "print(f\"Starting Extraction ({START_YEAR}-{END_YEAR})...\")\n",
        "\n",
        "for task in tasks:\n",
        "    print(f\"\\nProcessing {task['name']} (Station {task['station']}):\")\n",
        "    task_dfs = []\n",
        "\n",
        "    for year in range(START_YEAR, END_YEAR + 1):\n",
        "        df_year = fetch_dmi_year(year, task)\n",
        "        if not df_year.empty:\n",
        "            task_dfs.append(df_year)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    if task_dfs:\n",
        "        full_task_df = pd.concat(task_dfs)\n",
        "        # Remove duplicates caused by year overlap\n",
        "        full_task_df = full_task_df[~full_task_df.index.duplicated(keep='first')]\n",
        "        all_data.append(full_task_df)\n",
        "\n",
        "if not all_data:\n",
        "    print(\"No data retrieved.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nMerging all parameters...\")\n",
        "df_raw = pd.concat(all_data, axis=1)\n",
        "\n",
        "# --- 2. CLEANUP ---\n",
        "mask = (df_raw.index >= pd.Timestamp(f\"{START_YEAR}-01-01\", tz='UTC')) & \\\n",
        "       (df_raw.index <= pd.Timestamp(f\"{END_YEAR}-12-31 23:59:59\", tz='UTC'))\n",
        "df_raw = df_raw.loc[mask]\n",
        "\n",
        "# Interpolate missing 10-min slots\n",
        "df_raw = df_raw.interpolate(method='time', limit=6)\n",
        "\n",
        "if 'Global_Radiation_Wm2' in df_raw.columns:\n",
        "    df_raw['Global_Radiation_Wm2'] = df_raw['Global_Radiation_Wm2'].fillna(0).clip(lower=0)\n",
        "\n",
        "# --- 3. CALCULATE 10-YEAR 10-MINUTE AVERAGES ---\n",
        "print(\"Calculating 10-year 10-Minute Averages...\")\n",
        "\n",
        "if df_raw.index.tz is not None:\n",
        "    df_raw.index = df_raw.index.tz_convert(None)\n",
        "\n",
        "# Group by Month, Day, Hour, AND MINUTE\n",
        "grouped = df_raw.groupby([\n",
        "    df_raw.index.month,\n",
        "    df_raw.index.day,\n",
        "    df_raw.index.hour,\n",
        "    df_raw.index.minute\n",
        "]).mean()\n",
        "\n",
        "grouped.index.names = ['Month', 'Day', 'Hour', 'Minute']\n",
        "df_avg = grouped.reset_index()\n",
        "\n",
        "# Create dummy timestamp for display (using 2024 for Leap Year support)\n",
        "df_avg['Dummy_Timestamp'] = pd.to_datetime(\n",
        "    '2024-' + df_avg['Month'].astype(str) + '-' + df_avg['Day'].astype(str) + ' ' +\n",
        "    df_avg['Hour'].astype(str) + ':' + df_avg['Minute'].astype(str) + ':00',\n",
        "    errors='coerce'\n",
        ")\n",
        "df_avg = df_avg.dropna(subset=['Dummy_Timestamp']).sort_values('Dummy_Timestamp')\n",
        "\n",
        "# Format Output\n",
        "df_avg['Display_Date'] = df_avg['Dummy_Timestamp'].dt.strftime('%m-%d')\n",
        "df_avg['Display_Time'] = df_avg['Dummy_Timestamp'].dt.strftime('%H:%M')\n",
        "\n",
        "final_output = df_avg[['Display_Date', 'Display_Time', 'Temperature_C', 'Wind_Speed_ms', 'Global_Radiation_Wm2']]\n",
        "\n",
        "print(f\"Success! Created {len(final_output)} rows (10-min resolution).\")\n",
        "print(final_output.head())\n",
        "final_output.to_csv(\"Copenhagen_10Year_10Min_Average_2015-2024.csv\", index=False)"
      ]
    }
  ]
}