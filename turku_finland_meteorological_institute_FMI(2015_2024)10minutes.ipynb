{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "turku_finland_meteorological_institute_FMI(2015-2024)10minutes.ipynb",
      "authorship_tag": "ABX9TyNPk3dA3m4Q5sOFliVdzIxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Climatic_Data/blob/main/turku_finland_meteorological_institute_FMI(2015_2024)10minutes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxlyr4KCnLd0",
        "outputId": "1c700e2e-4b91-47bd-b3a5-f024481a13f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Hybrid Extraction for Turku (2015-2024)...\n",
            "\n",
            "--- Processing Year 2015 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2016 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52705 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52561 rows)\n",
            "\n",
            "--- Processing Year 2017 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2018 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2019 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2020 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52705 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52561 rows)\n",
            "\n",
            "--- Processing Year 2021 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2022 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2023 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52561 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52417 rows)\n",
            "\n",
            "--- Processing Year 2024 ---\n",
            "   > Fetching FMI Weather (Temp/Wind)... ...... Done (52705 rows)\n",
            "   > Fetching STRÅNG Solar...  Done (Upsampled to 52561 rows)\n",
            "\n",
            "Merging all years...\n",
            "Calculating 10-Year 10-Minute Averages...\n",
            "Success! Generated 52561 rows.\n",
            "  Display_Date Display_Time  Temperature_C  Wind_Speed_ms  \\\n",
            "0        01-01        00:00          -0.53       2.866667   \n",
            "1        01-01        00:10          -0.60       2.522222   \n",
            "2        01-01        00:20          -0.64       2.877778   \n",
            "3        01-01        00:30          -0.77       2.822222   \n",
            "4        01-01        00:40          -0.73       2.755556   \n",
            "\n",
            "   Global_Radiation_Wm2  \n",
            "0                   0.0  \n",
            "1                   0.0  \n",
            "2                   0.0  \n",
            "3                   0.0  \n",
            "4                   0.0  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "STATION_ID = \"100949\"  # Turku Artukainen\n",
        "LAT = \"60.45\"          # Turku Latitude\n",
        "LON = \"22.25\"          # Turku Longitude\n",
        "\n",
        "YEARS = range(2015, 2025)\n",
        "OUTPUT_FILE = \"Turku_10Yr_10Min_Averages_Hybrid.csv\"\n",
        "\n",
        "# --- PART 1: FMI WEATHER (Temp + Wind) ---\n",
        "def get_fmi_chunks(start_date, end_date):\n",
        "    s = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    e = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    chunks = []\n",
        "    curr = s\n",
        "    while curr < e:\n",
        "        nxt = min(curr + timedelta(days=7), e)\n",
        "        chunks.append((curr.strftime('%Y-%m-%dT%H:%M:%SZ'), nxt.strftime('%Y-%m-%dT%H:%M:%SZ')))\n",
        "        curr = nxt\n",
        "    return chunks\n",
        "\n",
        "def fetch_fmi_weather(year):\n",
        "    print(f\"   > Fetching FMI Weather (Temp/Wind)...\", end=\" \", flush=True)\n",
        "\n",
        "    start_str = f\"{year}-01-01\"\n",
        "    end_str = f\"{year+1}-01-01\"\n",
        "    chunks = get_fmi_chunks(start_str, end_str)\n",
        "\n",
        "    all_rows = []\n",
        "    params = {\n",
        "        \"service\": \"WFS\", \"version\": \"2.0.0\", \"request\": \"getFeature\",\n",
        "        \"storedquery_id\": \"fmi::observations::weather::simple\",\n",
        "        \"fmisid\": STATION_ID,\n",
        "        \"parameters\": \"t2m,ws_10min\",\n",
        "    }\n",
        "\n",
        "    for i, (s_ch, e_ch) in enumerate(chunks):\n",
        "        params[\"starttime\"] = s_ch\n",
        "        params[\"endtime\"] = e_ch\n",
        "\n",
        "        try:\n",
        "            r = requests.get(\"http://opendata.fmi.fi/wfs\", params=params, timeout=20)\n",
        "            if r.status_code == 200:\n",
        "                root = ET.fromstring(r.content)\n",
        "                ns = {'wfs': 'http://www.opengis.net/wfs/2.0', 'BsWfs': 'http://xml.fmi.fi/schema/wfs/2.0'}\n",
        "                for member in root.findall('.//wfs:member', ns):\n",
        "                    elm = member.find('.//BsWfs:BsWfsElement', ns)\n",
        "                    # FIX 1: Explicit 'is not None' check avoids DeprecationWarning\n",
        "                    if elm is not None:\n",
        "                        t = elm.find('BsWfs:Time', ns).text\n",
        "                        p = elm.find('BsWfs:ParameterName', ns).text\n",
        "                        v_node = elm.find('BsWfs:ParameterValue', ns)\n",
        "                        try:\n",
        "                            val = float(v_node.text)\n",
        "                            p_name = \"Temperature_C\" if p == \"t2m\" else \"Wind_Speed_ms\"\n",
        "                            all_rows.append({'Time': t, 'Type': p_name, 'Value': val})\n",
        "                        except: continue\n",
        "        except Exception: pass\n",
        "        if i % 10 == 0: print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "    if all_rows:\n",
        "        df = pd.DataFrame(all_rows)\n",
        "        # FIX 2: Handle Timezones correctly\n",
        "        # FMI returns UTC strings with 'Z'. We convert to datetime, then STRIP timezone to match STRÅNG.\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "        if df['Time'].dt.tz is not None:\n",
        "             df['Time'] = df['Time'].dt.tz_convert(None)\n",
        "\n",
        "        df = df.pivot_table(index='Time', columns='Type', values='Value', aggfunc='mean')\n",
        "\n",
        "        # Resample to 10min\n",
        "        df = df.resample('10min').mean().interpolate(limit=6)\n",
        "        print(f\" Done ({len(df)} rows)\")\n",
        "        return df\n",
        "    print(\" Failed.\")\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# --- PART 2: STRÅNG SOLAR (Model) ---\n",
        "def fetch_strang_solar(year):\n",
        "    print(f\"   > Fetching STRÅNG Solar...\", end=\" \", flush=True)\n",
        "\n",
        "    y_start = f\"{year}-01-01\"\n",
        "    y_end = f\"{year}-12-31\"\n",
        "\n",
        "    url = f\"https://opendata-download-metanalys.smhi.se/api/category/strang1g/version/1/geotype/point/lon/{LON}/lat/{LAT}/parameter/117/data.json\"\n",
        "    params = {'from': y_start.replace(\"-\", \"\"), 'to': y_end.replace(\"-\", \"\"), 'interval': 'hourly'}\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, params=params, timeout=30)\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()\n",
        "            records = [{'Time': pd.to_datetime(i['date_time']), 'Global_Radiation_Wm2': i['value']} for i in data]\n",
        "            df = pd.DataFrame(records)\n",
        "\n",
        "            # STRÅNG is also UTC, we make it naive to match FMI\n",
        "            if df['Time'].dt.tz is not None:\n",
        "                df['Time'] = df['Time'].dt.tz_convert(None)\n",
        "            else:\n",
        "                 # If it parsed as naive but is actually UTC, just leave it as naive UTC\n",
        "                 pass\n",
        "\n",
        "            df = df.set_index('Time').sort_index()\n",
        "\n",
        "            # UPSAMPLE: Hourly -> 10 Minute (Interpolated)\n",
        "            df = df.resample('10min').interpolate(method='time')\n",
        "            print(f\" Done (Upsampled to {len(df)} rows)\")\n",
        "            return df\n",
        "    except Exception as e: print(f\"Error: {e}\")\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "all_years_data = []\n",
        "\n",
        "print(f\"Starting Hybrid Extraction for Turku ({YEARS[0]}-{YEARS[-1]})...\")\n",
        "\n",
        "for year in YEARS:\n",
        "    print(f\"\\n--- Processing Year {year} ---\")\n",
        "\n",
        "    # 1. Get FMI Weather\n",
        "    df_weather = fetch_fmi_weather(year)\n",
        "\n",
        "    # 2. Get STRÅNG Solar\n",
        "    df_solar = fetch_strang_solar(year)\n",
        "\n",
        "    # 3. Merge\n",
        "    if not df_weather.empty and not df_solar.empty:\n",
        "        # Both indices are now Timezone-Naive. Safe to merge.\n",
        "        df_merged = pd.merge(df_weather, df_solar, left_index=True, right_index=True, how='inner')\n",
        "        all_years_data.append(df_merged)\n",
        "\n",
        "if all_years_data:\n",
        "    print(\"\\nMerging all years...\")\n",
        "    master_df = pd.concat(all_years_data)\n",
        "\n",
        "    # Solar Cleanup\n",
        "    if 'Global_Radiation_Wm2' in master_df.columns:\n",
        "        master_df['Global_Radiation_Wm2'] = master_df['Global_Radiation_Wm2'].fillna(0).clip(lower=0)\n",
        "\n",
        "    print(\"Calculating 10-Year 10-Minute Averages...\")\n",
        "\n",
        "    grouped = master_df.groupby([\n",
        "        master_df.index.month,\n",
        "        master_df.index.day,\n",
        "        master_df.index.hour,\n",
        "        master_df.index.minute\n",
        "    ]).mean()\n",
        "\n",
        "    grouped.index.names = ['Month', 'Day', 'Hour', 'Minute']\n",
        "    df_avg = grouped.reset_index()\n",
        "\n",
        "    # Dummy Timestamp for Sorting (using 2024)\n",
        "    df_avg['Dummy_Timestamp'] = pd.to_datetime(\n",
        "        '2024-' + df_avg['Month'].astype(str) + '-' + df_avg['Day'].astype(str) + ' ' +\n",
        "        df_avg['Hour'].astype(str) + ':' + df_avg['Minute'].astype(str) + ':00',\n",
        "        errors='coerce'\n",
        "    )\n",
        "    df_avg = df_avg.dropna(subset=['Dummy_Timestamp']).sort_values('Dummy_Timestamp')\n",
        "\n",
        "    df_avg['Display_Date'] = df_avg['Dummy_Timestamp'].dt.strftime('%m-%d')\n",
        "    df_avg['Display_Time'] = df_avg['Dummy_Timestamp'].dt.strftime('%H:%M')\n",
        "\n",
        "    final_cols = ['Display_Date', 'Display_Time', 'Temperature_C', 'Wind_Speed_ms', 'Global_Radiation_Wm2']\n",
        "    final_output = df_avg[[c for c in final_cols if c in df_avg.columns]]\n",
        "\n",
        "    print(f\"Success! Generated {len(final_output)} rows.\")\n",
        "    print(final_output.head())\n",
        "    final_output.to_csv(OUTPUT_FILE, index=False)\n",
        "else:\n",
        "    print(\"No data retrieved.\")"
      ]
    }
  ]
}